{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1: Import Libraries and Load Models\n",
    "from langchain_community.llms.ctransformers import CTransformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.docstore.in_memory import InMemoryDocstore\n",
    "import faiss\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=CTransformers(model = \"TheBloke/Llama-2-7b-GGML\",model_type=\"llama\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_texts(texts):\n",
    "    inputs=tokenizer(texts,return_tensors=\"pt\",truncation = True, padding = True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_example = embed_texts([\"test\"])\n",
    "embedding_dim = embedding_example.shape[1]\n",
    "\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "docstore = InMemoryDocstore()\n",
    "\n",
    "index_to_docstore_id = {}\n",
    "\n",
    "vectorstore = FAISS(embedding_function=embed_texts, index=index, docstore=docstore, index_to_docstore_id=index_to_docstore_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Prepare Your Documents\n",
    "documents = [\n",
    "    Document(page_content=\"I am Moguloju Sai, a Data Science graduate from Hyderabad, Telangana, with a solid foundation in Machine Learning, Data Science, and hands-on project work. With 4 months of internship experience, I have developed a strong technical background, eager to apply my analytical and technical skills to solve real-world problems and contribute to impactful data-driven solutions.\"),\n",
    "    Document(page_content=\"I have completed internships as a Junior Data Scientist at Coapps.ai, where I worked extensively with the Streamlit framework, focusing on a project aimed at detecting fake news using Machine Learning and NLP. This project allowed me to gain valuable experience in deploying sophisticated algorithms to address the challenge of information authenticity.\"),\n",
    "    Document(page_content=\"I have technical proficiency in Python, Java, R, MySQL, and various tools like Excel and Tableau. Additionally, I have certifications in Data Science with Python (NPTEL), Python Programming (Internshala), AWS Fundamentals (Coursera), and Machine Learning and Artificial Intelligence (EducateNXT).\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the documnets and add them to the vectorstore\n",
    "texts = [doc.page_content for doc in documents]\n",
    "embeddings = embed_texts(texts)\n",
    "\n",
    "for i, embedding in enumerate(embeddings):\n",
    "    index.add(np.array([embedding],dtype=np.float32))\n",
    "    index_to_docstore_id[i] = documents[i].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Simple Retriever\n",
    "def simple_retriever(query):\n",
    "    query_embedding = embed_texts([query])\n",
    "    D, I = index.search(query_embedding,k=1)\n",
    "    return index_to_docstore_id[I[0][0]] if len(I) > 0 and I[0][0] in index_to_docstore_id else \" No matching document found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RAG Chain\n",
    "class SimpleRetrievalQA:\n",
    "    def __init__(self, llm, retriever):\n",
    "        self.llm = llm\n",
    "        self.retriever = retriever\n",
    "        \n",
    "    def run(self, query):\n",
    "        context = self.retriever(query)\n",
    "        response = self.llm(f'Context: {context}\\n\\nQuestion: {query}\\n\\nAnswer:')\n",
    "        \n",
    "qa_chain = SimpleRetrievalQA(llm=llm, retriever = simple_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask Question Using the RAG Model\n",
    "question = \"Who is Moguloju Sai?\"\n",
    "\n",
    "# Get the answer from the RAG model\n",
    "answer = qa_chain.run(question)\n",
    "\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
